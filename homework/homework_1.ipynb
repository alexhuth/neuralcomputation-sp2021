{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "In this homework you are going to implement and test linear model fitting functions, and data quality checking functions. You will need to install (at least) python, jupyter, matplotlib, and numpy to do this assignment. Installing anaconda is a quick way to get all of those things.\n",
    "\n",
    "There are 4 problems worth a total of 37 points. The description for each problem will tell you how many points each part is worth.\n",
    "\n",
    "You should not need to edit the boilerplate code in this notebook, but wherever you see `## YOUR CODE HERE ##`, you should replace that with your own code (obviously).\n",
    "\n",
    "To turn in your homework, upload your finished `.ipynb` file to canvas. This homework is due before class on **4/7**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 - Gradient Descent (12 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make testing data\n",
    "\n",
    "def gd_make_data(nsamp=100, noise=0):    \n",
    "    # Generate a two dimensional stimulus (e.g two pixels) with correlations and 100 samples (e.g. points in time)\n",
    "    # First pixel data\n",
    "    x1 = np.random.randn(nsamp)\n",
    "\n",
    "    # Second pixel that is correlated with the first\n",
    "    x2 = .4 * x1 + .6 * np.random.randn(nsamp)\n",
    "\n",
    "    # Concatinate into a stimulus matrix - here rows are dimensions and columns are time points.\n",
    "    x = np.vstack([x1, x2])\n",
    "\n",
    "    ## Generate weights and the corresponding one dimensional response \n",
    "    # Set weights on each channel\n",
    "    b = np.array([1, 7])\n",
    "\n",
    "    # Make response of system - this is the output of our toy neuron\n",
    "    y = np.dot(x.T, b) + np.random.randn(nsamp) * noise\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "x, y = gd_make_data()\n",
    "\n",
    "# Plot timeseries\n",
    "plt.plot(x[0])\n",
    "plt.plot(x[1])\n",
    "plt.plot(y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to pretend we don't know h and make a search for h values by settting up \n",
    "# a range of potential values for h1 and h2\n",
    "\n",
    "b1, b2 = np.meshgrid(np.arange(-1, 10, .2), np.arange(-1, 10, .2))\n",
    "bs = np.vstack([b1.ravel(), b2.ravel()])\n",
    "\n",
    "# get responses from each set of weights\n",
    "ys = np.dot(x.T, bs)\n",
    "\n",
    "# calculate error between the response, y, and each of the possible responses, ys.  \n",
    "errfun = np.sum((y[:,None] - ys) ** 2, 0)\n",
    "\n",
    "# reshape for plotting\n",
    "errfun = errfun.reshape(b1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot contour of error surface. Note the shape of the surface is angled\n",
    "# because the two variable are correlated.\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(b1, b2, errfun, 50, colors='k', alpha=0.3);\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Gradient Descent (3 pts)\n",
    "One way to solve this problem is using gradient descent. Take the derivative of the error function, and then take small steps along that derivative (i.e. add the step multiplied by a small step size, `eps` to your estimate of beta).\n",
    "\n",
    "For this problem, the features are in the variable `x`, and the response is in the variable `y`.\n",
    "\n",
    "Write code that uses gradient descent to solve this problem. Store the estimated betas after each gradient step, and then plot the path that the gradient descent took (i.e. the values of all the betas along the way) on top of the error contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent!\n",
    "\n",
    "steps = 100 # how many steps to take\n",
    "eps = 0.001 # the size of each step\n",
    "\n",
    "b_est = np.array([0.0, 0.0]) # store your current estimate of beta here\n",
    "b_est_history = np.zeros([steps+1, 2]) # assume b_est_history[0] = result before you started\n",
    "\n",
    "for ii in range(steps):\n",
    "    ## YOUR CODE HERE ##\n",
    "\n",
    "\n",
    "## plot contour of error surface and your regression path\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(b1, b2, errfun, 50, colors='k', alpha=0.3)\n",
    "\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Coordinate Descent (3 pts)\n",
    "Remember that an alternative to gradient descent is coordinate descent, where you only change the one weight (out of the two betas in this problem) that had the largest derivative on each step.\n",
    "\n",
    "Write code that uses coordinate descent to solve this problem. Again, store the estimated betas after each step, and then plot the results on top of the error contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate descent!\n",
    "steps = 100 # how many steps to take\n",
    "eps = 0.001 # the size of each step\n",
    "\n",
    "b_est = np.array([0.0, 0.0])\n",
    "b_est_history = np.zeros([steps+1, 2])\n",
    "\n",
    "for ii in range(steps):\n",
    "    ## YOUR CODE HERE ##\n",
    "\n",
    "\n",
    "## plot contour of error surface and your regression path\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(b1, b2, errfun, 50, colors='k', alpha=0.3)\n",
    "\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Gradient descent with early stopping (3 pts)\n",
    "One way to regularize your regression solution is to stop doing gradient descent before you make it all the way to the bottom. This is done by checking the error after each step on a separate dataset (here called the validation set). This can be useful when the data is noisy (unlike the situation above, which was noiseless).\n",
    "\n",
    "For this problem the training features and responses (that you should use to update the weights) are in the variables `trnx` and `trny`. The validation features and responses (that you should use to test your model along the way) are in the variables `valx` and `valy`.\n",
    "\n",
    "Implement code to do gradient descent here, but now compute and store the mean squared error on both the validation and training datasets after each step. (You don't need to actually stop early, do the same number of steps as before.) \n",
    "\n",
    "Then plot the training and validation error as a function of step number. Explain the plot.\n",
    "\n",
    "Then plot the path that the gradient descent took on top of the error contours. Note that the contours are for the noiseless case, while the data you're using here is noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "heldout_data = np.load('gd-heldout.npz')\n",
    "trnx = heldout_data['trnx']\n",
    "trny = heldout_data['trny']\n",
    "valx = heldout_data['valx']\n",
    "valy = heldout_data['valy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent!\n",
    "\n",
    "steps = 100\n",
    "eps = 0.001\n",
    "\n",
    "b_est = np.array([0.0, 0.0])\n",
    "b_est_history = np.zeros([steps+1, 2])\n",
    "\n",
    "trn_err_history = np.zeros([steps])\n",
    "val_err_history = np.zeros([steps])\n",
    "\n",
    "for ii in range(steps):\n",
    "    ## YOUR CODE HERE ##\n",
    "\n",
    "## plot the training and validation error as a function of step number\n",
    "plt.figure()\n",
    "## YOUR CODE HERE ##\n",
    "plt.legend();\n",
    "\n",
    "print('Best step in held-out set:', val_err_history.argmin(), 'Weights:', b_est_history[val_err_history.argmin()])\n",
    "print('Where gradient descent ended up:', b_est_history[-1])\n",
    "\n",
    "## plot the betas along the way\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(b1, b2, errfun, 50, colors='k', alpha=0.3)\n",
    "\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain what's going on in the error plots here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Coordinate descent with early stopping (3 pts)\n",
    "Similarly, you can do coordinate descent with early stopping (or, at least, testing on another dataset along the way). Do that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate descent!\n",
    "\n",
    "steps = 100\n",
    "eps = 0.001\n",
    "\n",
    "b_est = np.array([0.0, 0.0])\n",
    "b_est_history = np.zeros([steps+1, 2])\n",
    "trn_err_history = np.zeros([steps])\n",
    "val_err_history = np.zeros([steps])\n",
    "\n",
    "for ii in range(steps):\n",
    "    ## YOUR CODE HERE ##\n",
    "\n",
    "## plot the training and validation error as a function of step number\n",
    "plt.figure()\n",
    "## YOUR CODE HERE ##\n",
    "plt.legend();\n",
    "\n",
    "print('Best step in held-out set:', val_err_history.argmin())\n",
    "print(b_est_history[val_err_history.argmin()])\n",
    "print(b_est_history[-1])\n",
    "\n",
    "## plot the beta path\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(b1, b2, errfun, 50, colors='k', alpha=0.3)\n",
    "\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "plt.axis('equal');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 - Regression: ordinary least squares (OLS) and ridge on a small problem (6 pts)\n",
    "Now that you've implemented gradient descent and coordinate descent, let's do the easy versions! For this problem you'll be finding analytic solutions to the ordinary least squares (OLS) problem and the ridge problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Solve the (noiseless) 2-feature problem with OLS. (2 pts)\n",
    "Then plot the solution on top of an error contour plot.\n",
    "\n",
    "Use the features `x` and responses `y` that were defined in the noiseless problem (2a) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ols = ## YOUR CODE HERE ##\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(b1, b2, errfun, 50, colors='k', alpha=0.3)\n",
    "## YOUR CODE HERE ##\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Solve the (noiseless) 2-feature problem with ridge (4 pts)\n",
    "Solve the regression problem using features `x` and responses `y` using ridge. Test the different ridge regularization coefficients (lambdas) given here. For each lambda, store the betas that you find. Then plot the resulting beta path on top of an error contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(0, 4, 10)\n",
    "betas_ridge = np.zeros((len(lambdas), 2))\n",
    "for ii in range(len(lambdas)):\n",
    "    ## YOUR CODE HERE ##\n",
    "\n",
    "\n",
    "## Plot the ridge solutions on the error contours\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.contour(b1, b2, errfun, 50, colors='k', alpha=0.3)\n",
    "\n",
    "## YOUR CODE HERE ##\n",
    "\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 - Regression on a high-dimensional problem (9 pts)\n",
    "For the last problem you're going to do regression on a dataset with lots of features and noise as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate high-dimensional data\n",
    "\n",
    "n_features = 400 # the number of features\n",
    "n_timepoints = 600 # the number of timepoints\n",
    "n_training = 450 # the number of timepoints that we'll use for training\n",
    "noise_level = 5.0 # how much noise to add\n",
    "\n",
    "# generate the \"true\" betas, the ones that will be used to generate the data\n",
    "beta_true = np.random.randn(n_features)\n",
    "\n",
    "# generate the feature matrix, x\n",
    "# this uses a trick to make the different features in x be pretty correlated\n",
    "u,s,vh = np.linalg.svd(np.random.randn(n_timepoints, n_features), full_matrices=False)\n",
    "x_all = (u*(s**5)).dot(vh)\n",
    "x_all /= x_all.max()\n",
    "\n",
    "# generate the responses, y = x . beta + noise\n",
    "y_all = x_all.dot(beta_true) + np.random.randn(n_timepoints) * noise_level\n",
    "\n",
    "# split x and y into training part (first n_training timepoints) ..\n",
    "x = x_all[:n_training]\n",
    "y = y_all[:n_training]\n",
    "\n",
    "# .. and validation part (remaining timepoints)\n",
    "x_val = x_all[n_training:]\n",
    "y_val = y_all[n_training:]\n",
    "\n",
    "# plot y, let's see what it looks like\n",
    "plt.plot(y_all);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) How well could we possibly do at this problem? (3 pts)\n",
    "\n",
    "#### i. Define a function to compute the mean squared error (MSE) between a signal $z$ and its estimate $\\hat{z}$ (1 pt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(z, z_hat):\n",
    "    return ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. What is the minimum possible MSE on the training set and on the validation set? (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trn_mse = ## YOUR CODE HERE ##\n",
    "best_val_mse = ## YOUR CODE HERE ##\n",
    "\n",
    "print('Best possible MSE on training set:')\n",
    "print(best_trn_mse)\n",
    "\n",
    "print('Best possible MSE on validation set:')\n",
    "print(best_val_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. What would MSE be on the training and validation sets if all $\\beta=0$? (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betazero_trn_mse = ## YOUR CODE HERE ##\n",
    "betazero_val_mse = ## YOUR CODE HERE ##\n",
    "\n",
    "print('MSE on training set with beta=0:')\n",
    "print(betazero_trn_mse)\n",
    "\n",
    "print('MSE on validation set with beta=0:')\n",
    "print(betazero_val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Solve the high-dimensional problem with OLS (1 pt)\n",
    "(Note that the feature matrix `x` is transposed here as compared to problem 3.)\n",
    "\n",
    "If you do this right, the training error should be _way_ better than the minimum possible. That is truly incredible. Unbelievable. Literally. And the validation error is much worse than what you would get from just guessing that $\\beta=0$. Explain why below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_ols = ## YOUR CODE HERE ##\n",
    "\n",
    "y_hat = ## YOUR CODE HERE ##\n",
    "y_val_hat = ## YOUR CODE HERE ##\n",
    "\n",
    "print('Training MSE:', mean_squared_error(y, y_hat))\n",
    "\n",
    "print('Validation MSE:', mean_squared_error(y_val, y_val_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explain what the heck is going on here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Solve high-dimensional problem with ridge (5 pts)\n",
    "\n",
    "#### i. Solve the regression problem $y = x \\beta$ using ridge regression. Try the different ridge coefficients (lambdas) as given here. For each lambda, store the MSE on the training dataset, the MSE on the validation dataset, and the betas. (2 pts)\n",
    "(Note again that `x` is transposed relative to problem 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-3, 5, 10) # let's check 10 lambdas between 10^-3 and 10^5. play with this range if you like\n",
    "betas_ridge = np.zeros((len(lambdas), n_features))\n",
    "trn_mse = np.zeros(len(lambdas))\n",
    "val_mse = np.zeros(len(lambdas))\n",
    "\n",
    "for ii in range(len(lambdas)):\n",
    "    ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Plot the training MSE and validation MSE as a function of lambda. Plot horizontal lines that show the theoretical minimum and maximum MSE (i.e. when beta=0) on the validation set, which you computed above. Explain what you see. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explanation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. For each feature, plot its weight (beta) as a function of lambda. Put all of these on the same plot. Explain what you see. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 - Cross-validation (10 pts)\n",
    "\n",
    "Cross-validation is the method that we can use to choose hyperparameters, such as the ridge penalty $\\lambda$ in ridge regression. It is an empirical technique that is incredibly effective, even if the data does not exactly fit the assumptions of your model (e.g. if the errors are not gaussian, etc.). You can read more about cross-validation [here](https://en.wikipedia.org/wiki/Cross-validation_(statistics%29).\n",
    "\n",
    "As a basic scheme, imagine that you have data that is split into two parts: training and test. Let's suppose you try a bunch of different ridge parameters by fitting models using the training data. If you check how well each model predicts the training data (that you used to generate the weights), then you'll get a bad answer: most likely the smallest ridge parameter will work best (you saw this in the last homework). If you check how well each model predicts the test data, then you're cheating: you're touching the test data before you're done model fitting. **Don't cheat by fitting hyperparameters using the test data!!** So obviously we need another way to check the ridge parameters.\n",
    "\n",
    "Now suppose that you further split the training dataset into two parts: the \"training\" set (yes it's the same name, get over it), and a \"validation\" set. Now you can train your models using the training data, check how well they work using the validation dataset, and use those numbers to pick your hyperparameter. Then, finally, you can use the whole training dataset and the best hyperparameter to fit a model that you'll use to try to predict the test data (which you haven't touched until now). No cheating! This is cross-validation.\n",
    "\n",
    "In this problem, you are going to use three different cross-validation methods to select $\\lambda$ for ridge regression.\n",
    "\n",
    "**BIG HINT**: The `np.delete` function is your best friend for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data!\n",
    "p1a_file = np.load('homework_1_p4_data.npz')\n",
    "x = p1a_file['x']\n",
    "y = p1a_file['y']\n",
    "x_test = p1a_file['x_test']\n",
    "y_test = p1a_file['y_test']\n",
    "\n",
    "n_training, n_features = x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Leave-one-out (LOO) cross-validation (3 pts)\n",
    "\n",
    "This is perhaps the simplest cross-validation method. Select one datapoint from the training set to be the validation set, then train on the other $n-1$ datapoints. Test on the remaining datapoint. Repeat this process for each datapoint, and then average the results.\n",
    "\n",
    "This works very well when the datapoints are independent, which is going to be the case in this first dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-3, 5, 10)\n",
    "val_ses = np.zeros((n_training, len(lambdas)))\n",
    "\n",
    "def ridge(x, y, lam):\n",
    "    \"\"\"This function does ridge regression with the stimuli x and responses y with\n",
    "    ridge parameter lam (short for lambda). It returns the weights.\n",
    "    This is definitely not the most efficient way to do this, but it's fine for now.\n",
    "    \"\"\"\n",
    "    n_features = x.shape[1]\n",
    "    beta_ridge = np.linalg.inv(x.T.dot(x) + lam * np.eye(n_features)).dot(x.T).dot(y)\n",
    "    return beta_ridge\n",
    "\n",
    "for t in range(n_training):\n",
    "    # split the training dataset into two parts: one with only point t,\n",
    "    # and one with all the other datapoints\n",
    "    x_trn = ## YOUR CODE HERE ##\n",
    "    y_trn = ## YOUR CODE HERE ##\n",
    "    \n",
    "    x_val = ## YOUR CODE HERE ##\n",
    "    y_val = ## YOUR CODE HERE ##\n",
    "    \n",
    "    for ii in range(len(lambdas)):\n",
    "        # fit model using x_trn & predict y_hal\n",
    "        y_val_hat = ## YOUR CODE HERE ##\n",
    "        \n",
    "        # store squared error in val_mses\n",
    "        val_ses[t,ii] = ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean squared error with each lambda, averaged across validation datapoints\n",
    "\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best lambda (i.e. the one with the least validation error), print it\n",
    "best_lambda = ## YOUR CODE HERE ##\n",
    "print(\"Best lambda:\", best_lambda)\n",
    "\n",
    "# Fit a model using the whole training set and the best lambda\n",
    "beta_hat = ## YOUR CODE HERE ##\n",
    "\n",
    "# Use that model to predict y_test\n",
    "y_test_hat = ## YOUR CODE HERE ##\n",
    "\n",
    "# Compute the MSE on the test dataset, print it\n",
    "test_mse = ## YOUR CODE HERE ##\n",
    "\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) $k$-fold cross-validation (3 pts)\n",
    "\n",
    "You may have noticed that LOO CV is quite slow. That's because it needs to fit one model per datapoint. If you have a lot of datapoint, that's just not gonna work! Further, as mentioned above, LOO only works well when your datapoints are independent. Suppose you're recording fMRI data. You know that the underlying BOLD signal is very low frequency--meaning that the individual datapoints are anything but independent.\n",
    "\n",
    "Another option is $k$-fold cross-validation. In this scheme, you split the training dataset into $k$ parts. Then you use $k-1$ of the parts to train the model, and use the $k$'th part as your validation dataset. Repeat this, holding out each part in turn. This means you only need to fit $k$ sets of models, instead of one for each datapoint.\n",
    "\n",
    "If your entire training dataset has $n$ datapoints, each \"fold\" should contain $\\frac{n}{k}$ datapoints, and each datapoint should only be in one fold. Assuming that $n/k$ is an integer, a nice way to do this is to break up the training dataset into $k$ contiguous parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6 # let's do 6 folds\n",
    "n_per_fold = n_training / k # number of datapoints per fold\n",
    "\n",
    "lambdas = np.logspace(-3, 5, 10)\n",
    "val_mses = np.zeros((k, len(lambdas)))\n",
    "\n",
    "\n",
    "for fold in range(k):\n",
    "    # split the training dataset into two parts: one with only the points in fold \"fold\"\n",
    "    # and one with all the other datapoints\n",
    "    \n",
    "    ## YOUR CODE HERE ##\n",
    "    \n",
    "    x_trn = ## YOUR CODE HERE ##\n",
    "    y_trn = ## YOUR CODE HERE ##\n",
    "    \n",
    "    x_val = ## YOUR CODE HERE ##\n",
    "    y_val = ## YOUR CODE HERE ##\n",
    "    \n",
    "    for ii in range(len(lambdas)):\n",
    "        # fit model using x_trn & predict y_val\n",
    "        y_val_hat = ## YOUR CODE HERE ##\n",
    "        \n",
    "        # store squared error in val_mses\n",
    "        val_mses[fold,ii] = ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MSE for each lambda, averaged across the folds\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best lambda, print it\n",
    "best_lambda = ## YOUR CODE HERE ##\n",
    "print(\"Best lambda:\", best_lambda)\n",
    "\n",
    "# Fit a model using the whole training set and the best lambda\n",
    "beta_hat = ## YOUR CODE HERE ##\n",
    "\n",
    "# Use that model to predict y_test\n",
    "y_test_hat = ## YOUR CODE HERE ##\n",
    "\n",
    "# Compute MSE on the test dataset, print it\n",
    "test_mse = ## YOUR CODE HERE ##\n",
    "\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Monte Carlo cross-validation (4 pts)\n",
    "\n",
    "One issue with $k$-fold CV is that the size of the validation set depends on the number of folds. If you want really stable estimates for your hyperparameter, you want to have a pretty large validation set, but also do a lot of folds. You can accomplish this by, on each iteration, randomly assigning some fraction of the training set to be the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_mc_iters = 50 # let's do 50 Monte Carlo iterations\n",
    "n_per_mc_iter = 50 # on each MC iteration, hold out 50 datapoints to be the validation set\n",
    "\n",
    "lambdas = np.logspace(-3, 5, 10)\n",
    "val_mses = np.zeros((n_training, len(lambdas)))\n",
    "\n",
    "\n",
    "for it in range(n_mc_iters):\n",
    "    # split the training dataset into two parts: one with a random selection of n_per_mc_iter points\n",
    "    # and one with all the other datapoints\n",
    "    \n",
    "    ## YOUR CODE HERE ##\n",
    "    \n",
    "    x_trn = ## YOUR CODE HERE ##\n",
    "    y_trn = ## YOUR CODE HERE ##\n",
    "    \n",
    "    x_val = ## YOUR CODE HERE ##\n",
    "    y_val = ## YOUR CODE HERE ##\n",
    "    \n",
    "    for ii in range(len(lambdas)):\n",
    "        # fit model using x_trn & predict y_val\n",
    "        # predict y_val\n",
    "        y_val_hat = ## YOUR CODE HERE ##\n",
    "        \n",
    "        # store squared error in val_mses\n",
    "        val_mses[it,ii] = ## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MSE for each lambda, averaged across the MC iterations\n",
    "\n",
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best lambda, print it\n",
    "best_lambda = ## YOUR CODE HERE ##\n",
    "print(\"Best lambda:\", best_lambda)\n",
    "\n",
    "# Fit a model using the whole training set and the best lambda\n",
    "beta_hat = ## YOUR CODE HERE ##\n",
    "\n",
    "# Use that model to predict y_test\n",
    "y_test_hat = ## YOUR CODE HERE ##\n",
    "\n",
    "# Compute the MSE, print it\n",
    "test_mse = ## YOUR CODE HERE ##\n",
    "\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Explanation here._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
